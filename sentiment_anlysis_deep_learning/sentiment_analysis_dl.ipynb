{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "%matplotlib inline\n",
    "color = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('reviews_Cell_Phones_and_Accessories_5.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120401325X</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>4</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>05 21, 2014</td>\n",
       "      <td>A30TL5EWN6DFXT</td>\n",
       "      <td>christina</td>\n",
       "      <td>Looks Good</td>\n",
       "      <td>1400630400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120401325X</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>01 14, 2014</td>\n",
       "      <td>ASY55RVNIL0UD</td>\n",
       "      <td>emily l.</td>\n",
       "      <td>Really great product.</td>\n",
       "      <td>1389657600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120401325X</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>06 26, 2014</td>\n",
       "      <td>A2TMXE2AFO7ONB</td>\n",
       "      <td>Erica</td>\n",
       "      <td>LOVE LOVE LOVE</td>\n",
       "      <td>1403740800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120401325X</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>4</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>10 21, 2013</td>\n",
       "      <td>AWJ0WZQYMYFQ4</td>\n",
       "      <td>JM</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1382313600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120401325X</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>5</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>02 3, 2013</td>\n",
       "      <td>ATX7CZYFXI1KW</td>\n",
       "      <td>patrice m rogoza</td>\n",
       "      <td>leopard home button sticker for iphone 4s</td>\n",
       "      <td>1359849600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  120401325X  [0, 0]        4   \n",
       "1  120401325X  [0, 0]        5   \n",
       "2  120401325X  [0, 0]        5   \n",
       "3  120401325X  [4, 4]        4   \n",
       "4  120401325X  [2, 3]        5   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  They look good and stick good! I just don't li...  05 21, 2014   \n",
       "1  These stickers work like the review says they ...  01 14, 2014   \n",
       "2  These are awesome and make my phone look so st...  06 26, 2014   \n",
       "3  Item arrived in great time and was in perfect ...  10 21, 2013   \n",
       "4  awesome! stays on, and looks great. can be use...   02 3, 2013   \n",
       "\n",
       "       reviewerID      reviewerName  \\\n",
       "0  A30TL5EWN6DFXT         christina   \n",
       "1   ASY55RVNIL0UD          emily l.   \n",
       "2  A2TMXE2AFO7ONB             Erica   \n",
       "3   AWJ0WZQYMYFQ4                JM   \n",
       "4   ATX7CZYFXI1KW  patrice m rogoza   \n",
       "\n",
       "                                     summary  unixReviewTime  \n",
       "0                                 Looks Good      1400630400  \n",
       "1                      Really great product.      1389657600  \n",
       "2                             LOVE LOVE LOVE      1403740800  \n",
       "3                                      Cute!      1382313600  \n",
       "4  leopard home button sticker for iphone 4s      1359849600  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> From the text analysis that we did in \"sentiment_analysis_ml\" we already know the nature of text, we will now proceed directly with text processing and will build a Deep Learning Model using that<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels=['asin', 'helpful','reviewTime','reviewerID','reviewerName','summary', 'unixReviewTime'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Let's bucketize the rating into 3 categories, namely: Positive, Neutral and Negative.<br>\n",
    "    Rating 5 will be marked as Positive<br>\n",
    "    Rating 3 & 4 will be bucktized together as Neutral<br>\n",
    "    Rating 2 & 1 will be now be bucktized together as Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(data):\n",
    "    \n",
    "    if data == 5:\n",
    "        return \"Positive\"\n",
    "    elif data == 4 or data == 3:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overall'] = df['overall'].apply(lambda x: create_bucket(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading <a href=\"http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\">GloVe</a> Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embed(file):\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "    if file == '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec':\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o)>100)\n",
    "    else:\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
    "        \n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = load_embed('glove.840B.300d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Now we should build our vocab keeping the frequency of each word in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def build_vocab(sentences):\n",
    "    fd = defaultdict(int)\n",
    "    for sentence in tqdm(sentences):\n",
    "        for word in sentence:\n",
    "            fd[word]+=1\n",
    "    return fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Let's create a function to check how many words in our vocab are actually present in out embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_intersection(vocab,embedding):\n",
    "    temp = {}\n",
    "    oov = {}\n",
    "    i = 0\n",
    "    j = 0\n",
    "    \n",
    "    for word in vocab.keys():\n",
    "        try:\n",
    "            temp[word] = embedding[word]\n",
    "            i+=vocab[word]\n",
    "        except:\n",
    "            oov[word] = vocab[word]\n",
    "            j+=vocab[word]\n",
    "            pass\n",
    "    \n",
    "    print(f\"Found embeddings for {(len(temp)/len(vocab)*100):.3f}% of vocab\")\n",
    "    print(f\"Found embeddings for {(i/(i+j))*100:.3f}% of all text\")\n",
    "    \n",
    "    sorted_x = sorted(oov.items(), key = lambda x: x[1])[::-1]\n",
    "    return sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194439/194439 [00:01<00:00, 124303.32it/s]\n",
      "100%|██████████| 194439/194439 [00:02<00:00, 83387.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 20.674% of vocab\n",
      "Found embeddings for 92.221% of all text\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "sentences = df['reviewText'].progress_apply(lambda x: x.split()).values\n",
    "vocab = build_vocab(sentences)\n",
    "oov = embed_intersection(vocab,embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Embeddings are available from 20.674% of our vocab, let's check top ten out of vocab words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('phone,', 13181),\n",
       " ('case,', 11001),\n",
       " (\"isn't\", 7554),\n",
       " (\"won't\", 7193),\n",
       " ('However,', 5724),\n",
       " ('charger.', 4914),\n",
       " (\"wasn't\", 4715),\n",
       " ('well,', 4665),\n",
       " (\"haven't\", 4322),\n",
       " (\"wouldn't\", 4185)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may happen that due the presence of puncatuation words might be the same as the one's present in embedding, also beacuse present of capital letters words might be getting out of vocab, let's fix all these issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lower_rev'] = df['reviewText'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But making the words in lower case can lead to loss of information as there are words whose embeddings are present in upper case only.\n",
    "\n",
    "We can fix this:\n",
    "\n",
    "* word.lower() takes the embedding of word if word.lower() doesn't have an embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_case(embedding,vocab):\n",
    "    count = 0\n",
    "    for word in vocab:\n",
    "        if word in embedding and word.lower() not in embedding:\n",
    "            embedding[word.lower()] = embedding[word]\n",
    "            count +=1\n",
    "    print(f'{count} no of words inserted into embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 20.674% of vocab\n",
      "Found embeddings for 92.221% of all text\n",
      "10061 no of words inserted into embedding\n",
      "Found embeddings for 20.911% of vocab\n",
      "Found embeddings for 92.253% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = embed_intersection(vocab,embedding)\n",
    "fix_case(embedding,vocab)\n",
    "oov = embed_intersection(vocab,embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the punctuations and contractions are causing the mismatch between our vocab and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
    "                       \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n",
    "                       \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\",\n",
    "                       \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                       \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "                       \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \n",
    "                       \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "                       \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n",
    "                       \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \n",
    "                       \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "                       \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "                       \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n",
    "                       \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "                       \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "                       \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
    "                       \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
    "                       \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \n",
    "                       \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "                       \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\",\n",
    "                       \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "                       \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n",
    "                       \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \n",
    "                       \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \n",
    "                       \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \n",
    "                       \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "                       \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \n",
    "                       \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n",
    "                       \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
    "                       \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \n",
    "                       \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \n",
    "                       \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \n",
    "                       \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \n",
    "                       \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\",\n",
    "                       \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \n",
    "                       \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                       \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \n",
    "                       \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\n",
    "                       \"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \n",
    "                       \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "                       \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cont_map(embedding):\n",
    "    known = []\n",
    "    for cont in contraction_mapping:\n",
    "        if cont in embedding:\n",
    "            known.append(cont)\n",
    "    return known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"can't\",\n",
       " \"'cause\",\n",
       " \"didn't\",\n",
       " \"doesn't\",\n",
       " \"don't\",\n",
       " \"I'd\",\n",
       " \"I'll\",\n",
       " \"I'm\",\n",
       " \"I've\",\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " \"it's\",\n",
       " \"ma'am\",\n",
       " \"o'clock\",\n",
       " \"that's\",\n",
       " \"you'll\",\n",
       " \"you're\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_map(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> It can be seen that not all contractions are present in the embeddings, we will now be replacing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_cont(sentence,mapping):\n",
    "    sentence = str(sentence)\n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for each in specials:\n",
    "        sentence = sentence.replace(each,\"'\")\n",
    "    sentence = \" \".join([mapping[word] if word in mapping else word for word in sentence.split(\" \")])\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fixed_rev'] = df['lower_rev'].apply(lambda x: fix_cont(x,contraction_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194439/194439 [00:02<00:00, 91979.84it/s]\n",
      "100%|██████████| 194439/194439 [00:02<00:00, 81440.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 18.541% of vocab\n",
      "Found embeddings for 92.753% of all text\n"
     ]
    }
   ],
   "source": [
    "sentences = df['fixed_rev'].progress_apply(lambda x: x.split()).values\n",
    "vocab = build_vocab(sentences)\n",
    "oov = embed_intersection(vocab,embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('phone,', 13345),\n",
       " ('case,', 11204),\n",
       " ('however,', 8158),\n",
       " ('well,', 5626),\n",
       " ('charger.', 5035),\n",
       " ('great,', 4202),\n",
       " ('it!', 3681),\n",
       " ('me,', 3677),\n",
       " ('on,', 3669),\n",
       " ('time,', 3645)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Now it's time to deal with puncuations and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_punt(sentence,punct):\n",
    "    \n",
    "    for p in punct:\n",
    "        sentence = sentence.replace(p, f' {p} ')\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fixed_rev'] = df['fixed_rev'].apply(lambda x: fix_punt(x,punct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194439/194439 [00:01<00:00, 110429.73it/s]\n",
      "100%|██████████| 194439/194439 [00:02<00:00, 88667.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 62.501% of vocab\n",
      "Found embeddings for 99.720% of all text\n"
     ]
    }
   ],
   "source": [
    "sentences = df['fixed_rev'].progress_apply(lambda x: x.split()).values\n",
    "vocab = build_vocab(sentences)\n",
    "oov = embed_intersection(vocab,embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see a huge improvement now embeddings are present for 99.72% of all the text in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bolse', 452),\n",
       " ('ismooth', 410),\n",
       " ('maxboost', 375),\n",
       " ('newtrent', 273),\n",
       " ('itorch', 268),\n",
       " ('000mah', 263),\n",
       " ('caseology', 260),\n",
       " ('zerolemon', 256),\n",
       " ('icarrier', 225),\n",
       " ('otterboxes', 222),\n",
       " ('easyacc', 209),\n",
       " ('nt90c', 191),\n",
       " ('sharkk', 190),\n",
       " ('zeetron', 180),\n",
       " ('frieq', 173),\n",
       " ('jackery', 162),\n",
       " ('incredicharge', 136),\n",
       " ('gopower', 135),\n",
       " ('hx550', 133),\n",
       " ('eargels', 131)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that now most of the out of vocab words are due to use of some slang or due to some spelling mistake.<br>\n",
    "__Note__:\n",
    "* We can further increase the intersection between our vocab and Glove by fixing speeling mistake, but we will left this step for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels=['reviewText', 'lower_rev'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the embeddings covers almost all of our text data, let move ahead and start building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_len(data):\n",
    "    len_str = data['fixed_rev'].apply(lambda x : len(x.split()))\n",
    "    return np.mean(len_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>fixed_rev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>they look good and stick good !  i just do not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>these stickers work like the review says they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>these are awesome and make my phone look so st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>item arrived in great time and was in perfect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>awesome !  stays on ,  and looks great .  can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    overall                                          fixed_rev\n",
       "0   Neutral  they look good and stick good !  i just do not...\n",
       "1  Positive  these stickers work like the review says they ...\n",
       "2  Positive  these are awesome and make my phone look so st...\n",
       "3   Neutral  item arrived in great time and was in perfect ...\n",
       "4  Positive  awesome !  stays on ,  and looks great .  can ..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Lenth of reviews given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107.9483385534795"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab) + 1\n",
    "max_len = 108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    \n",
    "    t = Tokenizer(filters='')\n",
    "    t.fit_on_texts(data)\n",
    "    data = t.texts_to_sequences(data)\n",
    "    data = pad_sequences(data,maxlen = max_len)\n",
    "    return data, t.word_index,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, word_index, tokenizer = process_data(df['fixed_rev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le= LabelEncoder()\n",
    "df['overall'] = le.fit_transform(df['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['overall'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_binary = to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideally we should divide the dataset in three subsets Test, Train & Validation so as to build more robust model but for the sake of exam will be dividing it into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y_binary,test_size=0.1,random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174995, 108)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's make our embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embed_mat(embedding,word_index,vocab_size):\n",
    "    embds = np.stack(embedding.values())\n",
    "    emb_mean,emb_std = embds.mean(), embds.std()\n",
    "    embed_size = embds.shape[1]\n",
    "    word_index = word_index\n",
    "    embedding_matrix = np.random.normal(emb_mean,emb_std,(vocab_size,embed_size))\n",
    "    \n",
    "    for word,i in word_index.items():\n",
    "        if i>=vocab_size:\n",
    "            continue\n",
    "        embedding_vec = embedding.get(word)\n",
    "        if embedding_vec is not None:\n",
    "            embedding_matrix[i] = embedding_vec\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadil/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_matrix = make_embed_mat(embedding,word_index,vocab_size)\n",
    "del word_index, vocab, sentences\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86536, 300)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Embedding, CuDNNGRU, Bidirectional, GlobalAveragePooling1D\n",
    "from keras.layers import GlobalMaxPooling1D,concatenate,Input, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Building a GRU based deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(embedding_matrix, embed_size=300, loss='categorical_crossentropy'):\n",
    "    \n",
    "    inp = Input(shape=(max_len,))\n",
    "    x = Embedding(input_dim=vocab_size,output_dim=embed_size,weights=[embedding_matrix],trainable=False)(inp)\n",
    "    x = Bidirectional(CuDNNGRU(128,return_sequences=True))(x)\n",
    "    x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "    avg_pl = GlobalAveragePooling1D()(x)\n",
    "    max_pl = GlobalMaxPooling1D()(x)\n",
    "    concat = concatenate([avg_pl,max_pl])\n",
    "    dense  = Dense(64, activation=\"relu\")(concat)\n",
    "    dense  = Dropout(rate = 0.7)(dense)\n",
    "    output = Dense(3, activation=\"softmax\")(dense)\n",
    "    \n",
    "    model = Model(inputs=inp, output=output)\n",
    "    model.compile(loss=loss,optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0906 17:14:36.279181 139997342480192 deprecation_wrapper.py:119] From /home/aadil/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0906 17:14:36.305133 139997342480192 deprecation_wrapper.py:119] From /home/aadil/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0906 17:14:36.308362 139997342480192 deprecation_wrapper.py:119] From /home/aadil/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0906 17:14:36.348826 139997342480192 deprecation_wrapper.py:119] From /home/aadil/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0906 17:14:36.349436 139997342480192 deprecation_wrapper.py:119] From /home/aadil/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "/home/aadil/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "W0906 17:14:41.950510 139997342480192 deprecation.py:506] From /home/aadil/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0906 17:14:41.951416 139997342480192 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "/home/aadil/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \n",
      "W0906 17:14:41.987671 139997342480192 deprecation_wrapper.py:119] From /home/aadil/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = make_model(embed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 108)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 108, 300)     25960800    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 108, 256)     330240      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 108, 128)     123648      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           16448       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            195         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,431,331\n",
      "Trainable params: 470,531\n",
      "Non-trainable params: 25,960,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = ModelCheckpoint('model.h5',monitor='val_acc',mode='max',save_best_only='True',verbose=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=2, verbose=1, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model on Nvidia GTX 1050Ti GPU, locally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0906 17:14:42.255306 139997342480192 deprecation.py:323] From /home/aadil/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 174995 samples, validate on 19444 samples\n",
      "Epoch 1/15\n",
      "174995/174995 [==============================] - 83s 476us/step - loss: 0.8344 - acc: 0.6106 - val_loss: 0.7276 - val_acc: 0.6635\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66350, saving model to model.h5\n",
      "Epoch 2/15\n",
      "174995/174995 [==============================] - 81s 464us/step - loss: 0.7228 - acc: 0.6757 - val_loss: 0.6732 - val_acc: 0.6980\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.66350 to 0.69800, saving model to model.h5\n",
      "Epoch 3/15\n",
      "174995/174995 [==============================] - 81s 462us/step - loss: 0.6808 - acc: 0.7014 - val_loss: 0.6334 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.69800 to 0.72238, saving model to model.h5\n",
      "Epoch 4/15\n",
      "174995/174995 [==============================] - 81s 464us/step - loss: 0.6532 - acc: 0.7175 - val_loss: 0.6111 - val_acc: 0.7353\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.72238 to 0.73534, saving model to model.h5\n",
      "Epoch 5/15\n",
      "174995/174995 [==============================] - 83s 475us/step - loss: 0.6349 - acc: 0.7265 - val_loss: 0.6004 - val_acc: 0.7377\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.73534 to 0.73766, saving model to model.h5\n",
      "Epoch 6/15\n",
      "174995/174995 [==============================] - 81s 465us/step - loss: 0.6212 - acc: 0.7336 - val_loss: 0.5869 - val_acc: 0.7438\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.73766 to 0.74383, saving model to model.h5\n",
      "Epoch 7/15\n",
      "174995/174995 [==============================] - 81s 462us/step - loss: 0.6079 - acc: 0.7395 - val_loss: 0.5781 - val_acc: 0.7469\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.74383 to 0.74686, saving model to model.h5\n",
      "Epoch 8/15\n",
      "174995/174995 [==============================] - 82s 470us/step - loss: 0.5983 - acc: 0.7454 - val_loss: 0.5843 - val_acc: 0.7451\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.74686\n",
      "Epoch 9/15\n",
      "174995/174995 [==============================] - 80s 459us/step - loss: 0.5889 - acc: 0.7500 - val_loss: 0.5760 - val_acc: 0.7491\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.74686 to 0.74913, saving model to model.h5\n",
      "Epoch 10/15\n",
      "174995/174995 [==============================] - 79s 449us/step - loss: 0.5801 - acc: 0.7535 - val_loss: 0.5865 - val_acc: 0.7468\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.74913\n",
      "Epoch 11/15\n",
      "174995/174995 [==============================] - 78s 447us/step - loss: 0.5716 - acc: 0.7579 - val_loss: 0.5678 - val_acc: 0.7525\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.74913 to 0.75247, saving model to model.h5\n",
      "Epoch 12/15\n",
      "174995/174995 [==============================] - 78s 447us/step - loss: 0.5644 - acc: 0.7622 - val_loss: 0.5560 - val_acc: 0.7578\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.75247 to 0.75782, saving model to model.h5\n",
      "Epoch 13/15\n",
      "174995/174995 [==============================] - 78s 444us/step - loss: 0.5585 - acc: 0.7636 - val_loss: 0.5544 - val_acc: 0.7578\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.75782\n",
      "Epoch 14/15\n",
      "174995/174995 [==============================] - 78s 444us/step - loss: 0.5511 - acc: 0.7671 - val_loss: 0.5523 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.75782 to 0.76121, saving model to model.h5\n",
      "Epoch 15/15\n",
      "174995/174995 [==============================] - 78s 444us/step - loss: 0.5449 - acc: 0.7707 - val_loss: 0.5653 - val_acc: 0.7541\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.76121\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, \n",
    "                    validation_data=[X_test, y_test], callbacks=[checkpoints, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__:\n",
    "__Scope of improvement__:\n",
    "\n",
    "* Architecture can be changed instead of using GRU, LSTM can be used it will give better result but will be more computationally expensive to train\n",
    "\n",
    "* More layers can be added with the combination of some dense layers, it could further boost the performance(Beware of over-fitting)\n",
    "* Use of <a href=\"https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf\"> Attention Model</a> gives promising results in these kind of usecases.\n",
    "* BERT and XLnet can be expiremented with which may produce more robust models and can give more promising results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(history.history['acc'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_acc'], label='Test Accuracy')\n",
    "plt.legend(('Train Acc', 'Val Acc'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0906 17:39:32.284107 139997342480192 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 108)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 108, 300)     25960800    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 108, 256)     330240      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 108, 128)     123648      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           16448       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            195         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,431,331\n",
      "Trainable params: 470,531\n",
      "Non-trainable params: 25,960,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19444/19444 [==============================] - 3s 152us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test,batch_size=512, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9775175e-01, 3.9597657e-01, 4.0627176e-01],\n",
       "       [3.4335138e-05, 3.1976182e-02, 9.6798944e-01],\n",
       "       [1.1641518e-04, 3.6585547e-02, 9.6329802e-01],\n",
       "       [7.7630496e-03, 2.6969406e-01, 7.2254288e-01],\n",
       "       [6.2355548e-02, 5.8340317e-01, 3.5424134e-01],\n",
       "       [1.3594091e-04, 9.0558529e-02, 9.0930551e-01],\n",
       "       [4.0617511e-03, 1.9149785e-01, 8.0444038e-01],\n",
       "       [7.6413774e-03, 4.9092937e-01, 5.0142920e-01],\n",
       "       [3.3241759e-06, 1.2059247e-02, 9.8793739e-01],\n",
       "       [9.2018499e-06, 4.3849792e-02, 9.5614105e-01]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the threshold for predecting the class of a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def tweak_threshold(pred, truth):\n",
    "    thresholds = []\n",
    "    scores = []\n",
    "    for thresh in np.arange(0.1, 0.75, 0.01):\n",
    "        thresh = np.round(thresh, 2)\n",
    "        thresholds.append(thresh)\n",
    "        score = accuracy_score(truth, (pred>thresh).astype(int))\n",
    "        scores.append(score)\n",
    "    return np.max(scores), thresholds[np.argmax(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scored 0.7413 for threshold 0.49 with treated texts on validation data\n"
     ]
    }
   ],
   "source": [
    "score_val, threshold_val = tweak_threshold(pred, y_test)\n",
    "\n",
    "print(f\"Scored {round(score_val, 4)} for threshold {threshold_val} with treated texts on validation data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating predictions for all the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tokenizer.texts_to_sequences(df['fixed_rev'])\n",
    "pred = pad_sequences(pred,maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194439/194439 [==============================] - 27s 141us/step\n"
     ]
    }
   ],
   "source": [
    "pred_final = model.predict(pred,batch_size=512, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred_sentiment'] = np.argmax(pred_final, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Neutral', 'Positive'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred_sentiment'] = le.inverse_transform(df['pred_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overall'] = le.inverse_transform(df['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>fixed_rev</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>they look good and stick good !  i just do not...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>these stickers work like the review says they ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>these are awesome and make my phone look so st...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>item arrived in great time and was in perfect ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>awesome !  stays on ,  and looks great .  can ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>these make using the home button easy .  my da...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Positive</td>\n",
       "      <td>came just as described .  .  it does not come ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Negative</td>\n",
       "      <td>it worked for the first week then it only char...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Positive</td>\n",
       "      <td>good case ,  solid build .  protects phone all...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Positive</td>\n",
       "      <td>this is a fantastic case .  very stylish and p...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Positive</td>\n",
       "      <td>this case fits perfectly on the s4 and keeps m...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Positive</td>\n",
       "      <td>this is the first battery case i have had for ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Positive</td>\n",
       "      <td>performs exactly as advertised  .  it is very ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Positive</td>\n",
       "      <td>unlike most of the rechargeable battery cases ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Positive</td>\n",
       "      <td>just what i needed .  i needed a phone case fo...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Positive</td>\n",
       "      <td>when there is no outlets ,  or chargers near b...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Positive</td>\n",
       "      <td>it works great .  does not heat up like crazy ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Positive</td>\n",
       "      <td>surprisingly ,  this inexpensive version works...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Positive</td>\n",
       "      <td>i have tested this against the griffin dual ou...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Negative</td>\n",
       "      <td>it worked great for the first couple of weeks ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Positive</td>\n",
       "      <td>i love that it has two ports for my phone and ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Positive</td>\n",
       "      <td>just what you need ,  i am always having to ch...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>does not have the need amps to charge things l...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>they are nothing special for sure ,  but it is...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>i have several chargers .  have more than one ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     overall                                          fixed_rev pred_sentiment\n",
       "0    Neutral  they look good and stick good !  i just do not...        Neutral\n",
       "1   Positive  these stickers work like the review says they ...       Positive\n",
       "2   Positive  these are awesome and make my phone look so st...       Positive\n",
       "3    Neutral  item arrived in great time and was in perfect ...        Neutral\n",
       "4   Positive  awesome !  stays on ,  and looks great .  can ...       Positive\n",
       "5    Neutral  these make using the home button easy .  my da...       Positive\n",
       "6   Positive  came just as described .  .  it does not come ...       Positive\n",
       "7   Negative  it worked for the first week then it only char...       Negative\n",
       "8   Positive  good case ,  solid build .  protects phone all...       Positive\n",
       "9   Positive  this is a fantastic case .  very stylish and p...       Positive\n",
       "10  Positive  this case fits perfectly on the s4 and keeps m...       Positive\n",
       "11  Positive  this is the first battery case i have had for ...       Positive\n",
       "12  Positive  performs exactly as advertised  .  it is very ...       Positive\n",
       "13  Positive  unlike most of the rechargeable battery cases ...       Positive\n",
       "14  Positive  just what i needed .  i needed a phone case fo...       Positive\n",
       "15  Positive  when there is no outlets ,  or chargers near b...       Positive\n",
       "16  Positive  it works great .  does not heat up like crazy ...       Positive\n",
       "17  Positive  surprisingly ,  this inexpensive version works...       Positive\n",
       "18  Positive  i have tested this against the griffin dual ou...       Positive\n",
       "19  Negative  it worked great for the first couple of weeks ...       Negative\n",
       "20  Positive  i love that it has two ports for my phone and ...       Positive\n",
       "21  Positive  just what you need ,  i am always having to ch...       Positive\n",
       "22   Neutral  does not have the need amps to charge things l...        Neutral\n",
       "23   Neutral  they are nothing special for sure ,  but it is...        Neutral\n",
       "24   Neutral  i have several chargers .  have more than one ...       Positive"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The End.Thanks for reading!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
